{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting for Capilano University Enrollment Data\n",
    "\n",
    "This notebook processes enrollment data from Capilano University, converts it into time series format,\n",
    "and applies various forecasting models (Seasonal Naive, ETS, ARIMA). The results are logged to\n",
    "Weights & Biases for visualization and comparison.\n",
    "\n",
    "Original Work: Jiaqi Li (jiaqili@capilanou.ca)  \n",
    "Author: Eric Drechsler (dr.eric.drechsler@gmail.com)  \n",
    "Version: 250301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup and Module Imports\n",
    "\n",
    "This cell is responsible for setting up the Python environment and importing all the necessary modules and libraries required for the time series analysis.\n",
    "\n",
    "First, it imports standard Python libraries:\n",
    "- `logging`: Used for logging information, warnings, and errors during the execution of the script. This is crucial for debugging and monitoring the process.\n",
    "- `os`: Provides a way of using operating system dependent functionality, such as interacting with the file system.\n",
    "- `typing`: Used for type hinting, which improves code readability and helps catch type-related errors early on. Specifically, it imports `Any`, `Dict`, `List`, `Optional`, and `Tuple` for defining the types of variables and function arguments.\n",
    "\n",
    "Next, it imports external libraries:\n",
    "- `hydra`: A powerful configuration management library that allows for structured configuration through YAML files and command-line overrides. This aligns with the README's mention of using Hydra for configuration management.\n",
    "- `pandas`: A fundamental library for data manipulation and analysis, particularly for working with structured data like CSV files, which are mentioned in the `data_loader.py` description.\n",
    "- `pyrootutils`: A utility library for managing project structure and paths, as described in the README's project structure section.\n",
    "- `omegaconf`: Part of the Hydra ecosystem, it's used for working with configurations in a structured way.\n",
    "\n",
    "The code then uses `pyrootutils.setup_root()` to establish the project's root directory. This is important for ensuring that the script can find necessary files and modules regardless of the current working directory. The parameters passed to `setup_root()` indicate that it should search for a `.project_root` file, use an environment variable if set, load `.env` files, and ensure the project directory is added to the Python path.\n",
    "\n",
    "Following this, the script imports specific functions from the modules within the `capu_time_series_analysis` package, as outlined in the \"Modules Explained\" section of the README:\n",
    "- From `data_loader.py`: `add_to_consolidated_df`, `load_data`, and `prepare_time_series`, which are responsible for loading, preparing, and structuring the enrollment data.\n",
    "- From `evaluation.py`: `analyze_residuals` and `evaluate_forecasts`, which provide tools for assessing the performance and validity of the forecasting models.\n",
    "- From `models.py`: `fit_models`, which implements the time series forecasting models as described in the README.\n",
    "- From `visualization.py`: `log_results_to_wandb`, which handles logging results and visualizations to Weights & Biases, as mentioned in the \"Enhanced Visualization\" section of the README.\n",
    "\n",
    "Finally, the cell configures the logging system. It sets the logging level to `INFO`, specifies the format of the log messages (including timestamp, logger name, level, and message), and sets the date format. It then gets the root logger, which will be used to record events during the script's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell sets up the environment, imports necessary modules, and configures\n",
    "# logging\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import hydra\n",
    "import pandas as pd\n",
    "import pyrootutils\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "ROOT_PATH = pyrootutils.setup_root(\n",
    "    search_from=os.getcwd(),\n",
    "    indicator=\".project_root\",\n",
    "    project_root_env_var=True,\n",
    "    dotenv=True,\n",
    "    pythonpath=True,\n",
    "    cwd=True,\n",
    ")\n",
    "\n",
    "# This is the main function for processing time series data\n",
    "from capu_time_series_analysis.utils import process_timeseries\n",
    "from capu_time_series_analysis.visualization import log_results_to_wandb\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "cfg = {\n",
    "    \"input_file\": \"${hydra:runtime.cwd}/data/input/capu_enrolment_data_200820-202310_v20230213.csv\",\n",
    "    \"plot_dir\": \"${hydra:runtime.cwd}/output/plots\",  # TODO exclude plot storage in ipynb\n",
    "    \"levels\": [\"CapU\", \"AS\"],\n",
    "    # \"levels\": [\"CapU\", \"AS\", \"BPS\", \"EHHD\", \"FAA\", \"GCS\"],\n",
    "    \"residencies\": [\"Domestic\", \"International\"],\n",
    "    \"metrics\": [\"Headcount\"],\n",
    "    # \"metrics\": [\"Headcount\", \"CourseEnrolment\", \"AttemptedCredits\"],\n",
    "    \"forecast_steps\": 9,\n",
    "    \"models\": {\n",
    "        \"seasonal_naive_params\": {\"seasonal_periods\": 3},\n",
    "        \"ets_params\": {\n",
    "            \"seasonal\": \"add\",\n",
    "            \"damped_trend\": False,\n",
    "        },\n",
    "        \"arima_params\": {\n",
    "            \"seasonal\": True,\n",
    "            \"m\": 3,\n",
    "            \"d\": 0,\n",
    "            \"D\": 0,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process time series\n",
    "consolidated_df, evaluation_results, residual_diagnostics = process_timeseries(\n",
    "    cfg[\"input_file\"],\n",
    "    cfg[\"metrics\"],\n",
    "    cfg[\"residencies\"],\n",
    "    cfg[\"levels\"],\n",
    "    forecast_steps=cfg[\"forecast_steps\"],\n",
    "    model_params=cfg[\"models\"],\n",
    ")\n",
    "\n",
    "# Create evaluation dataframe\n",
    "evaluation_df = pd.DataFrame(evaluation_results)\n",
    "logger.info(f\"Created evaluation dataframe with {len(evaluation_df)} entries\")\n",
    "\n",
    "# Create residual diagnostics dataframe\n",
    "residual_df = pd.DataFrame(residual_diagnostics)\n",
    "logger.info(f\"Created residual diagnostics dataframe with {len(residual_df)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log results to wandb\n",
    "logger.info(\"Logging results to Weights & Biases\")\n",
    "log_results_to_wandb(\n",
    "    consolidated_df, evaluation_df, residual_df, cfg[\"metrics\"], cfg[\"levels\"], cfg[\"residencies\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
