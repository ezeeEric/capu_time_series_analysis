{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting for Capilano University Enrollment Data\n",
    "\n",
    "This notebook processes enrollment data from Capilano University, converts it into time series format,\n",
    "and applies various forecasting models (Seasonal Naive, ETS, ARIMA). The results are logged to\n",
    "Weights & Biases for visualization and comparison.\n",
    "\n",
    "Original Work: Jiaqi Li (jiaqili@capilanou.ca)  \n",
    "Author: Eric Drechsler (dr.eric.drechsler@gmail.com)  \n",
    "Version: 250301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup and Module Imports\n",
    "\n",
    "This cell is responsible for setting up the Python environment and importing all\n",
    "the necessary modules and libraries required for the time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell sets up the environment, imports necessary modules, and configures\n",
    "# logging\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pyrootutils\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "ROOT_PATH = pyrootutils.setup_root(\n",
    "    search_from=os.getcwd(),\n",
    "    indicator=\".project_root\",\n",
    "    project_root_env_var=True,\n",
    "    dotenv=True,\n",
    "    pythonpath=True,\n",
    "    cwd=True,\n",
    ")\n",
    "\n",
    "# This is the main function for processing time series data\n",
    "from capu_time_series_analysis.utils import process_timeseries\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data\n",
    "\n",
    "We rely on a datafile that contains enrollment data for Capilano University. The\n",
    "data is stored in a CSV file which is part of the repository. The data is loaded\n",
    "into a pandas DataFrame and displayed in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After cloning the repository in your setup cell\n",
    "\n",
    "# Define path to the input data file in the cloned repository\n",
    "data_path = \"data/input/capu_enrolment_data_200820-202310_v20230213.csv\"\n",
    "\n",
    "# Verify the file exists\n",
    "import os\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    print(f\"Found input data file at: {data_path}\")\n",
    "\n",
    "    # Preview the data\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f\"Warning: Could not find data file at {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "This configuration dictionary controls the behavior of the time series analysis pipeline:\n",
    "\n",
    "### Data Sources and Output Settings\n",
    "- `input_file`: Specifies the path to the data file (set dynamically to `data_path`)\n",
    "- `plot_dir`: Directory where generated plots will be saved (currently \"output/plotssss\")\n",
    "- `save_plots`: Boolean flag (False) that controls whether plots are saved to disk\n",
    "\n",
    "### Analysis Dimensions\n",
    "- `levels`: Limits analysis to specific academic units (\"CapU\", \"AS\")\n",
    "  - Commented code shows additional units that could be included (BPS, EHHD, FAA, GCS)\n",
    "- `residencies`: Student types to analyze (\"Domestic\", \"International\")\n",
    "- `metrics`: Data metrics to analyze (currently only \"Headcount\")\n",
    "  - Commented code shows additional metrics that could be included (CourseEnrolment, AttemptedCredits)\n",
    "- `forecast_steps`: Number of future time periods to forecast (9)\n",
    "\n",
    "### Model Configuration\n",
    "Parameters for each of the three forecasting models:\n",
    "\n",
    "#### Seasonal Naive Model\n",
    "- `seasonal_periods`: 3 (indicates quarterly/trimester data)\n",
    "\n",
    "#### ETS (Exponential Smoothing State Space) Model\n",
    "- `seasonal`: \"add\" (additive seasonality component)\n",
    "- `damped_trend`: False (trend component is not dampened)\n",
    "\n",
    "#### ARIMA (AutoRegressive Integrated Moving Average) Model\n",
    "- `seasonal`: True (includes seasonal component)\n",
    "- `m`: 3 (seasonal period length - quarters/trimesters)\n",
    "- `d`: 0 (no differencing for trend component)\n",
    "- `D`: 0 (no differencing for seasonal component)\n",
    "\n",
    "The configuration focuses on analyzing enrollment headcount data across different university departments and student residency types, with models specifically tuned for trimester academic data patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "cfg = {\n",
    "    \"input_file\": data_path,\n",
    "    \"plot_dir\": \"output/plotssss\",  # TODO exclude plot storage in ipynb\n",
    "    \"save_plots\": False,\n",
    "    # \"levels\": [\"CapU\", \"AS\"],\n",
    "    \"levels\": [\"CapU\", \"AS\", \"BPS\", \"EHHD\", \"FAA\", \"GCS\"],\n",
    "    \"residencies\": [\"Domestic\", \"International\"],\n",
    "    # \"metrics\": [\"Headcount\"],\n",
    "    \"metrics\": [\"Headcount\", \"CourseEnrolment\", \"AttemptedCredits\"],\n",
    "    \"forecast_steps\": 9,\n",
    "    \"models\": {\n",
    "        \"seasonal_naive_params\": {\"seasonal_periods\": 3},\n",
    "        \"ets_params\": {\n",
    "            \"seasonal\": \"add\",\n",
    "            \"damped_trend\": False,\n",
    "        },\n",
    "        \"arima_params\": {\n",
    "            \"seasonal\": True,\n",
    "            \"m\": 3,\n",
    "            \"d\": 0,\n",
    "            \"D\": 0,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "The time series processing is done inside the `process_timeseries` function, in\n",
    "which data for different combinations of metrics, residencies, and levels is\n",
    "analysed, forecasted, and evaluated.\n",
    "\n",
    "This function processes each combination of metrics, residencies, and levels\n",
    "through the following steps:\n",
    "\n",
    "1. Loads data from the input file for the specific combination\n",
    "2. Prepares and splits the time series into training and test sets\n",
    "3. Fits three forecasting models: Seasonal Naive, ETS, and ARIMA\n",
    "4. Analyzes residuals for each model to evaluate their fit quality\n",
    "5. Generates forecasts for the test period to validate model performance\n",
    "6. Creates future forecasts for the specified number of steps ahead\n",
    "7. Evaluates forecast accuracy on the test set using multiple metrics\n",
    "8. Consolidates all results into a single dataframe for easy analysis\n",
    "\n",
    "The process is repeated for all combinations of metrics, residencies, and levels,\n",
    "resulting in a comprehensive analysis across all specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process time series\n",
    "consolidated_df, evaluation_results, residual_diagnostics = process_timeseries(\n",
    "    cfg[\"input_file\"],\n",
    "    cfg[\"metrics\"],\n",
    "    cfg[\"residencies\"],\n",
    "    cfg[\"levels\"],\n",
    "    forecast_steps=cfg[\"forecast_steps\"],\n",
    "    model_params=cfg[\"models\"],\n",
    "    save_plots=cfg[\"save_plots\"],\n",
    "    plots_dir=cfg[\"plot_dir\"],\n",
    ")\n",
    "\n",
    "# Create evaluation dataframe\n",
    "evaluation_df = pd.DataFrame(evaluation_results)\n",
    "logger.info(f\"Created evaluation dataframe with {len(evaluation_df)} entries\")\n",
    "\n",
    "# Create residual diagnostics dataframe\n",
    "residual_df = pd.DataFrame(residual_diagnostics)\n",
    "logger.info(f\"Created residual diagnostics dataframe with {len(residual_df)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter = consolidated_df[\"Entry_Type\"] == \"Train\"\n",
    "test_filter = consolidated_df[\"Entry_Type\"] == \"Test\"\n",
    "actual_filter = consolidated_df[\"Model\"] == \"Actual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_df[test_filter & actual_filter].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_df[test_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Results DataFrame\n",
    "All results are stored in a consolidated pandas DataFrame with the following columns: \n",
    "\n",
    "- `Analysis_Type`: Combination of metric, residency, and level\n",
    "- `Residency`: Student type (Domestic, International)\n",
    "- `Level`: Academic unit (CapU, AS, etc.)\n",
    "- `Timestamp`: Date of the enrollment data\n",
    "- `Model`: Forecasting model used (Seasonal Naive, ETS, ARIMA, Actual for input data)\n",
    "- `Entry_Type`: Type of data (Train, Test, Forecast)\n",
    "- `Entry`: Value of the data point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidated_df.value_counts([\"Analysis_Type\", \"Residency\", \"Level\", \"Timestamp\", \"Model\", \"Entry_Type\"],sort=False)\n",
    "for col in [\"Analysis_Type\", \"Residency\", \"Level\", \"Model\", \"Entry_Type\"]:\n",
    "    print(consolidated_df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section is concerned with analyzing the results of the time series\n",
    "analysis. The functions below are specific to the notebook and are used to\n",
    "generate plots and tables that summarize the results of the analysis.\n",
    "\n",
    "Firstly, we import the necessary modules and libraries for the visualisation.\n",
    "The plotting functions are defined in a helper module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Results\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from capu_time_series_analysis.plotting import (\n",
    "    display_residual_plots,\n",
    "    plot_evaluation_metrics,\n",
    "    plot_time_series_combination,\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Visualization\n",
    "\n",
    "This plot shows time series data for a specific combination of academic level, residency status, and metric. The visualization includes:\n",
    "\n",
    "- **Blue Line**: Actual historical values used for training\n",
    "- **Green Line**: Actual values in the test period \n",
    "- **Dashed Lines**: Model forecasts for the test period (allows comparison with actual values)\n",
    "- **Dotted Lines**: Future forecasts beyond available data\n",
    "\n",
    "This visualization helps you:\n",
    "- Compare performance of different models (Seasonal Naive, ETS, ARIMA)\n",
    "- Evaluate how well each model captures seasonal patterns and trends\n",
    "- Identify which model produces the most realistic forecasts\n",
    "\n",
    "Use the interactive dropdown menus to explore different combinations of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dropdown widget for interactive visualization if in Colab\n",
    "try:\n",
    "    from ipywidgets import Dropdown, interact\n",
    "\n",
    "    # Get unique values for dropdowns\n",
    "    levels_list = consolidated_df[\"Level\"].unique().tolist()\n",
    "    residencies_list = consolidated_df[\"Residency\"].unique().tolist()\n",
    "    metrics_list = consolidated_df[\"Analysis_Type\"].unique().tolist()\n",
    "\n",
    "    # Create interactive widget\n",
    "    @interact(\n",
    "        level=Dropdown(options=levels_list, description=\"Level:\"),\n",
    "        residency=Dropdown(options=residencies_list, description=\"Residency:\"),\n",
    "        metric=Dropdown(options=metrics_list, description=\"Metric:\"),\n",
    "    )\n",
    "    def plot_interactive(level, residency, metric):\n",
    "        plot_time_series_combination(consolidated_df, level, residency, metric)\n",
    "\n",
    "except ImportError:\n",
    "    # If not in an interactive environment, just plot a sample\n",
    "    sample_level = consolidated_df[\"Level\"].unique()[0]\n",
    "    sample_residency = consolidated_df[\"Residency\"].unique()[0]\n",
    "    sample_metric = consolidated_df[\"Analysis_Type\"].unique()[0]\n",
    "\n",
    "    print(f\"Plotting sample combination: {sample_level} - {sample_residency} - {sample_metric}\")\n",
    "    plot_time_series_combination(consolidated_df, sample_level, sample_residency, sample_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics\n",
    "\n",
    "These bar charts compare the performance of each forecasting model (Seasonal Naive, ETS, ARIMA) across all combinations using standard error metrics:\n",
    "\n",
    "- **RMSE (Root Mean Square Error)**: Emphasizes larger errors (lower is better)\n",
    "- **MAE (Mean Absolute Error)**: Average absolute difference between predictions and actuals (lower is better)\n",
    "- **MAPE (Mean Absolute Percentage Error)**: Average percentage error (lower is better)\n",
    "\n",
    "The charts help identify:\n",
    "- Which model performs best for each data combination\n",
    "- Consistent patterns in model performance across different segments\n",
    "- The magnitude of improvement between baseline and more complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all three metrics\n",
    "metrics = [\"MAE\", \"RMSE\", \"MAPE\"]\n",
    "for metric in metrics:\n",
    "    try:\n",
    "        plot_evaluation_metrics(evaluation_df, metric)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting {metric}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Diagnostics\n",
    "\n",
    "These plots examine the residuals (errors) of each model to assess their statistical validity:\n",
    "\n",
    "- **Residuals Plot**: Shows residual values over time - ideally should look like random noise around zero\n",
    "- **Actual vs. Fitted Plot**: Compares actual values with model predictions\n",
    "- **Statistical Tests**: \n",
    "  - Mean Residual (should be close to zero)\n",
    "  - Standard Deviation of Residuals\n",
    "  - Ljung-Box p-value (tests for autocorrelation - p>0.05 suggests white noise)\n",
    "  - White Noise Test result\n",
    "\n",
    "Good models should have residuals that:\n",
    "- Are randomly distributed with no patterns\n",
    "- Have a mean close to zero\n",
    "- Show no significant autocorrelation\n",
    "- Pass the white noise test\n",
    "\n",
    "These diagnostics help validate that a model has captured all significant patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to display residual diagnostics (if they include plots)\n",
    "try:\n",
    "    display_residual_plots(residual_df)\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying residual plots: {e}\")\n",
    "\n",
    "    # Fallback: Display residual statistics if plots aren't available\n",
    "    print(\"\\nFallback: Displaying residual statistics:\")\n",
    "    summary_stats = residual_df[\n",
    "        [\n",
    "            \"Level\",\n",
    "            \"Residency\",\n",
    "            \"Analysis_Type\",\n",
    "            \"Model\",\n",
    "            \"Mean_Residual\",\n",
    "            \"Std_Residual\",\n",
    "            \"White_Noise\",\n",
    "        ]\n",
    "    ].copy()\n",
    "    display(summary_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Results Explorer\n",
    "\n",
    "This is a stab at a comprehensive tool allows you to explore all aspects of the analysis in one place:\n",
    "\n",
    "- **Time Series View**: Visualizes forecasts against actual values\n",
    "- **Evaluation Metrics View**: Compares model performance metrics\n",
    "- **Residual Diagnostics View**: Examines model validity through residual analysis\n",
    "\n",
    "Use the dropdown menus to select:\n",
    "- Academic level (Undergraduate, Graduate, etc.)\n",
    "- Residency status (Domestic, International, etc.)\n",
    "- Metric type (Headcount, FTE, etc.)\n",
    "- View type (which aspect of the analysis to examine)\n",
    "\n",
    "This interactive explorer makes it easy to drill down into specific combinations and understand model performance in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Interactive Results Explorer (works in Colab)\n",
    "try:\n",
    "    from ipywidgets import interact, widgets\n",
    "\n",
    "    def explore_results(consolidated_df, evaluation_df, residual_df):\n",
    "        \"\"\"Interactive widget to explore all results\"\"\"\n",
    "\n",
    "        levels = consolidated_df[\"Level\"].unique().tolist()\n",
    "        residencies = consolidated_df[\"Residency\"].unique().tolist()\n",
    "        metrics = consolidated_df[\"Analysis_Type\"].unique().tolist()\n",
    "\n",
    "        level_dropdown = widgets.Dropdown(options=levels, description=\"Level:\")\n",
    "        residency_dropdown = widgets.Dropdown(options=residencies, description=\"Residency:\")\n",
    "        metric_dropdown = widgets.Dropdown(options=metrics, description=\"Metric:\")\n",
    "\n",
    "        tab_dropdown = widgets.Dropdown(\n",
    "            options=[\"Time Series\", \"Evaluation Metrics\", \"Residual Diagnostics\"],\n",
    "            description=\"View:\",\n",
    "        )\n",
    "\n",
    "        def update_view(level, residency, metric, view):\n",
    "            if view == \"Time Series\":\n",
    "                plot_time_series_combination(consolidated_df, level, residency, metric)\n",
    "\n",
    "            elif view == \"Evaluation Metrics\":\n",
    "                # Filter evaluation df for this combination\n",
    "                subset = evaluation_df[\n",
    "                    (evaluation_df[\"Level\"] == level)\n",
    "                    & (evaluation_df[\"Residency\"] == residency)\n",
    "                    & (evaluation_df[\"Analysis_Type\"] == metric)\n",
    "                ]\n",
    "\n",
    "                if not subset.empty:\n",
    "                    # Create comparison bar chart\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    metrics_to_plot = [\n",
    "                        col for col in [\"RMSE\", \"MAE\", \"MAPE\"] if col in subset.columns\n",
    "                    ]\n",
    "\n",
    "                    for i, met in enumerate(metrics_to_plot):\n",
    "                        plt.subplot(1, len(metrics_to_plot), i + 1)\n",
    "                        sns.barplot(x=\"Model\", y=met, data=subset)\n",
    "                        plt.title(f\"{met} by Model\")\n",
    "                        plt.xticks(rotation=45)\n",
    "\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "                    # Display table\n",
    "                    display(subset)\n",
    "                else:\n",
    "                    print(\"No evaluation data for this combination\")\n",
    "\n",
    "            elif view == \"Residual Diagnostics\":\n",
    "                # Filter residual df for this combination\n",
    "                subset = residual_df[\n",
    "                    (residual_df[\"Level\"] == level)\n",
    "                    & (residual_df[\"Residency\"] == residency)\n",
    "                    & (residual_df[\"Analysis_Type\"] == metric)\n",
    "                ]\n",
    "\n",
    "                if not subset.empty:\n",
    "                    for _, row in subset.iterrows():\n",
    "                        model = row[\"Model\"]\n",
    "                        print(f\"\\n## {model} Model\")\n",
    "\n",
    "                        stats_info = (\n",
    "                            f\"Mean Residual: {row['Mean_Residual']:.4f}\\n\"\n",
    "                            f\"Std Residual: {row['Std_Residual']:.4f}\\n\"\n",
    "                            f\"Ljung-Box p-value: {row['Ljung_Box_pvalue']:.4f}\\n\"\n",
    "                            f\"White Noise Test: {'Passed' if row['White_Noise'] else 'Failed'}\"\n",
    "                        )\n",
    "                        print(stats_info)\n",
    "\n",
    "                        # Check if residual plots are available and display them\n",
    "                        if \"Residuals_Plot\" in row and not pd.isna(row[\"Residuals_Plot\"]):\n",
    "                            display(\n",
    "                                HTML(\n",
    "                                    f'<img src=\"data:image/png;base64,{row[\"Residuals_Plot\"]}\" width=\"700px\">'\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "                        if \"Actual_Fitted_Plot\" in row and not pd.isna(row[\"Actual_Fitted_Plot\"]):\n",
    "                            display(\n",
    "                                HTML(\n",
    "                                    f'<img src=\"data:image/png;base64,{row[\"Actual_Fitted_Plot\"]}\" width=\"700px\">'\n",
    "                                )\n",
    "                            )\n",
    "                else:\n",
    "                    print(\"No residual data for this combination\")\n",
    "\n",
    "        # Create the interactive widget\n",
    "        interact(\n",
    "            update_view,\n",
    "            level=level_dropdown,\n",
    "            residency=residency_dropdown,\n",
    "            metric=metric_dropdown,\n",
    "            view=tab_dropdown,\n",
    "        )\n",
    "\n",
    "    # Use the interactive explorer\n",
    "    explore_results(consolidated_df, evaluation_df, residual_df)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Interactive widgets are only available in Jupyter/Colab environments\")\n",
    "    # Provide a non-interactive alternative\n",
    "    sample_level = consolidated_df[\"Level\"].unique()[0]\n",
    "    sample_residency = consolidated_df[\"Residency\"].unique()[0]\n",
    "    sample_metric = consolidated_df[\"Analysis_Type\"].unique()[0]\n",
    "\n",
    "    plot_time_series_combination(consolidated_df, sample_level, sample_residency, sample_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
